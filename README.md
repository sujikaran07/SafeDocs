# SafeDocs - Complete Documentation

## Overview

SafeDocs is an AI-powered file security scanner and sanitizer that detects malicious content in documents (PDF, DOCX, XLSX, etc.) and provides cleaned versions.

---

## How It Works

### 1. **Upload & Scan**
- User uploads a file
- ML models analyze the file:
  - **LightGBM:** Primary classifier (70% weight)
  - **Deep Learning:** Neural network patterns
  - **Random Forest:** Ensemble learning
  - **Rule Engine:** Keyword matching (6000+ malware terms)

### 2. **Verdict Decision**

**Evidence-Based Logic:**
```python
if file has JavaScript/macros:
    verdict = "MALICIOUS"
elif high severity findings:
    verdict = "MALICIOUS"
elif medium findings + score > 70%:
    verdict = "MALICIOUS"
elif risk score > 85%:
    verdict = "MALICIOUS"
else:
    verdict = "BENIGN"
```

**NOT based on arbitrary threshold!**

### 3. **Sanitization (Malicious Files Only)**

If verdict = MALICIOUS:
- Remove JavaScript
- Remove auto-actions (OpenAction, AA)
- Remove macros/VBA
- Scrub 6000+ malware keywords
- Remove annotations
- Strip metadata

If verdict = BENIGN:
- Return original file unchanged (no sanitization needed)

---

## Understanding Results

### **Risk Score vs Verdict**

| Metric | Meaning | Example |
|--------|---------|---------|
| **Risk Score** | ML model's suspicion level<br/>How complex/unusual | 60% = "Complex structure" |
| **Verdict** | Actual decision<br/>Does it have threats? | BENIGN = "No malicious code found" |

**Example:**
- **Scanned invoice:** 55% risk, BENIGN âœ“ (complex but safe)
- **PDF with JS:** 40% risk, MALICIOUS âœ— (simple but dangerous)

**Verdict is what matters!** Risk score is just extra information.

### **Color Coding**

| Verdict | Color | Regardless of Score |
|---------|-------|---------------------|
| MALICIOUS | ðŸ”´ RED | Even if 35%, 48%, or 99% |
| BENIGN | ðŸŸ¢ GREEN | Even if 60%, 55%, or 20% |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚  Next.js 15 + React
â”‚   (TypeScript)  â”‚  Port 3000
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js API   â”‚  /api/scan, /api/download
â”‚   Routes        â”‚  Authentication, DB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Python        â”‚  FastAPI + Uvicorn
â”‚   Engine        â”‚  Port 8000
â”‚   - ML Models   â”‚  LightGBM, TensorFlow
â”‚   - Sanitizers  â”‚  PyPDF2, pikepdf
â”‚   - Features    â”‚  12 features extracted
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚  Neon Database
â”‚   (Prisma)      â”‚  Scan results, users
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Features Fixed

### âœ… **Evidence-Based Verdicts**
- No longer just threshold (>50% = malicious)
- Checks for actual JavaScript, macros, suspicious patterns
- Combination of findings + ML confidence

### âœ… **Benign Files Not Sanitized**
- Only malicious files are processed
- Benign files returned unchanged
- **Fixes:** White screen bug on downloads

### âœ… **Color Matching Verdict**
- RED = MALICIOUS (even if 48% score)
- GREEN = BENIGN (even if 60% score)
- **Fixed:** Case-insensitive verdict checks

### âœ… **JavaScript Detection**
- Checks both finding IDs AND text content
- Catches "Suspicious strings: javascript"
- **Fixed:** Files with JS mentions now flagged

### âœ… **Download URLs Fixed**
- No more `/api/api/` double paths
- Proper file retrieval from storage
- Detailed error logging

---

## Running the Project

### **Development:**

1. **Start Database:**
   ```bash
   # Already running on Neon cloud
   ```

2. **Start Python Engine:**
   ```bash
   cd platform
   npm run engine:dev
   # Runs on http://localhost:8000
   ```

3. **Start Frontend:**
   ```bash
   cd platform
   npm run dev
   # Runs on http://localhost:3000
   ```

### **Production:**

Deploy to Vercel (frontend) + separate Python backend deployment.

---

## Files Structure

```
SafeDocs/
â”œâ”€â”€ platform/              # Next.js frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ api/      # Next.js API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”‚   â”œâ”€â”€ scan/
â”‚   â”‚   â”‚   â””â”€â”€ scanreport/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ lib/
â”‚   â”œâ”€â”€ prisma/
â”‚   â”‚   â””â”€â”€ schema.prisma
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ engine/               # Python ML engine (ORGANIZED!)
â”‚   â”œâ”€â”€ api/             # FastAPI servers
â”‚   â”‚   â”œâ”€â”€ api_stateless.py  # Main server (port 8000)
â”‚   â”‚   â”œâ”€â”€ api_server.py     # Alternative server
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ db.py
â”‚   â”‚   â”œâ”€â”€ schemas.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”‚
â”‚   â”œâ”€â”€ core/            # Core scanning logic
â”‚   â”‚   â”œâ”€â”€ scan_file.py      # Main scanning
â”‚   â”‚   â”œâ”€â”€ features_runtime.py
â”‚   â”‚   â””â”€â”€ safedocs_lightgbm.py
â”‚   â”‚
â”‚   â”œâ”€â”€ sanitizers/      # File sanitizers
â”‚   â”‚   â”œâ”€â”€ sanitize_pdf.py   # PDF (6000+ keywords)
â”‚   â”‚   â”œâ”€â”€ sanitize_ooxml.py
â”‚   â”‚   â””â”€â”€ sanitize_rtf.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/           # Utility scripts
â”‚   â”‚   â”œâ”€â”€ report_utils.py
â”‚   â”‚   â”œâ”€â”€ predict_only.py
â”‚   â”‚   â””â”€â”€ debug_model.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/          # ML model files
â”‚   â”œâ”€â”€ scripts/         # Additional scripts
â”‚   â”œâ”€â”€ out/             # Temporary storage
â”‚   â”œâ”€â”€ main.py          # Entry point
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ README.md            # This file
```

---

## Common Issues & Solutions

### **1. "File missing or expired" on download**
**Cause:** Download URL has `/api/api/` or file not saved
**Fix:** âœ… Fixed - URL construction corrected

### **2. Downloaded file shows white screen**
**Cause:** Sanitizer broke benign files
**Fix:** âœ… Only sanitize malicious files now

### **3. BENIGN verdict but 60% risk - confusing**
**Cause:** Misunderstood what risk score means
**Fix:** âœ… Documentation explains difference

### **4. JavaScript file marked BENIGN**
**Cause:** Only checked finding ID, not text
**Fix:** âœ… Now checks both ID and content

### **5. Dashboard shows wrong colors**
**Cause:** Case-sensitive `verdict === "malicious"` check
**Fix:** âœ… `.toLowerCase()` used everywhere

---

## Testing

### **Test with Malicious Files:**

Use samples from:
- **MalwareBazaar:** https://bazaar.abuse.ch/browse/
- **Contagio Dump:** http://contagiodump.blogspot.com/
- **Created sample:** `test_samples/malicious_valid.pdf` (has JavaScript)

### **Test with Benign Files:**

Upload normal documents:
- Scanned PDFs
- Invoices
- Resumes
- Forms

**Expected:**
- Complex files may show 50-70% risk
- Verdict should be BENIGN
- Files download perfectly unchanged

---

## Technical Details

### **ML Model:**
- **Type:** LightGBM Gradient Boosting
- **Features:** 12 extracted features
- **Training:** 10,000+ malware samples
- **Accuracy:** ~85% on test set

### **Sanitization:**
- **PDF:** PyPDF2 + pikepdf fallback
- **OOXML:** python-docx/openpyxl
- **RTF:** Custom parser
- **Keywords:** 6000+ malware terms removed

### **Performance:**
- **Scan time:** 0.5-2 seconds per file
- **Max file size:** 100MB
- **Supported types:** PDF, DOCX, XLSX, PPTX, RTF

---

## Security Notes

1. **Files are deleted after 48 hours** (privacy)
2. **User authentication required** (no public access)
3. **Rate limiting enabled** (via Arcjet)
4. **Files isolated** (temporary storage)
5. **No execution** (static analysis only)

---

## Credits

- **ML Models:** LightGBM, TensorFlow
- **PDF Processing:** PyPDF2, pikepdf
- **Frontend:** Next.js 15, React, Framer Motion
- **Backend:** FastAPI, Prisma, PostgreSQL

---

## License

Private project - All rights reserved.
